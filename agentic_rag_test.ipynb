{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-nomic in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.1.3)\n",
      "Requirement already satisfied: langchain_community in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: tiktoken in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: langchainhub in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.5.7)\n",
      "Requirement already satisfied: langchain in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: langgraph in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.2.23)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.27-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tavily-python in /Users/flychuban/miniconda3/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: gpt4all in /Users/flychuban/miniconda3/lib/python3.10/site-packages (2.8.2)\n",
      "Requirement already satisfied: firecrawl-py in /Users/flychuban/miniconda3/lib/python3.10/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dotenv in /Users/flychuban/miniconda3/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.40 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain-nomic) (0.3.2)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.1.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain-nomic) (3.1.2)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain-nomic) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (0.1.125)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (1.26.3)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchainhub) (24.1)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchainhub) (2.32.0.20240914)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (1.2.2)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (0.110.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (3.6.6)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (1.66.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (0.9.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (3.10.7)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from chromadb) (13.7.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langgraph) (1.0.10)\n",
      "Requirement already satisfied: websockets in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from firecrawl-py) (13.0.1)\n",
      "Requirement already satisfied: nest-asyncio in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from firecrawl-py) (1.5.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: anyio in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.25.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (0.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2.40->langchain-nomic) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (8.1.7)\n",
      "Requirement already satisfied: jsonlines in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (0.7.2)\n",
      "Requirement already satisfied: pandas in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.1.4)\n",
      "Requirement already satisfied: pyarrow in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (14.0.2)\n",
      "Requirement already satisfied: pyjwt in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.9.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.0.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.25.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.12.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.40->langchain-nomic) (2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/flychuban/miniconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Downloading langgraph-0.2.27-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langgraph\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.2.23\n",
      "    Uninstalling langgraph-0.2.23:\n",
      "      Successfully uninstalled langgraph-0.2.23\n",
      "Successfully installed langgraph-0.2.27\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph tavily-python gpt4all firecrawl-py python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = 'llama3.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD BLOGPOSTS FROM INTERNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETRIEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_community.vectorstores.utils import  filter_complex_metadata\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Public urls to the blog post\n",
    "urls = [\n",
    "    \"https://elsys-bg.org/priem/den-na-otvorenite-vrati\",\n",
    "    \"https://tuesfest.bg/\",\n",
    "    \"https://hacktues.bg/\"\n",
    "]\n",
    "\n",
    "\n",
    "firecrawl_api_key = os.getenv('FIRECRAWL_API_KEY')\n",
    "\n",
    "# Load the documents\n",
    "docs = [FireCrawlLoader(api_key=firecrawl_api_key, url=url, mode=\"scrape\").load() for url in urls]\n",
    "\n",
    "# Flatten the list of lists\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=512, chunk_overlap=50)\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Filter out complex metadata and ensure proper document format\n",
    "filtered_docs = []\n",
    "for doc in doc_splits:\n",
    "    # Ensure the doc is instance of Document and has proper metadata\n",
    "    if isinstance(doc, Document) and hasattr(doc, 'metadata'):\n",
    "        clean_metadata = {k: v for k, v in doc.metadata.items() if isinstance(v, (str, int, float, bool))}\n",
    "        filtered_docs.append(Document(page_content=doc.page_content, metadata=clean_metadata))\n",
    "        \n",
    "# Add to vector DB\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=filtered_docs,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use Retrieval Grader for checking wheter the retrieved documents are fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETRIEVAL GRADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import  PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "#LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are a grader assessing relevance of a retrieved document to a user question. \n",
    "    If the document contains keywords related to the user question, grade it as a relevant. It does not need to bea stringent test. The goal is to filter out erroneous retrievals.\\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the user question. \\n\n",
    "    Provide the binary score as a JSON string with a single key 'score' and no premable or explanaiton.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieval document: \\n \\n {document} \\n\\n\n",
    "    Here is the user question: \\n \\n {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>,\n",
    "    \"\"\",\n",
    "    input_variables=[\"questions\", \"document\"],\n",
    ")\n",
    "\n",
    "# Define the grader using overloading pipeline\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "user_question = \"When was the first Hack TUES?\"\n",
    "docs = retriever.invoke(user_question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": user_question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Hack TUES was in 2014. I don't have the exact date, but it's mentioned as a \"10-ТО ЮБИЛЕЙНО ИЗДАНИЕ\" which means 10th anniversary edition.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import  PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the questions.\n",
    "    If you don't know the answer, respond with 'I don't know'. Use three sentences maximum and keep the answers concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>,\n",
    "    \"\"\",\n",
    "    input_variables=[\"questions\", \"document\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Post processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain \n",
    "reg_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "user_question = \"When was the first Hack TUES?\"\n",
    "docs = retriever.invoke(user_question)\n",
    "generation = reg_chain.invoke({\"question\": user_question, \"context\": format_docs(docs)})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HALLUCINATION GRADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'no'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0, format=\"json\")\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assesing whether an answer is grounded in / supported by a set of facts. Give a binary score \n",
    "    'yes' or 'no' to indicate whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the facts:\n",
    "    \\n -------- \\n \n",
    "    {documents}\n",
    "    \\n -------- \\n\n",
    "    Here is the answer: {generation} <|eot_id|><|start_header_id|>assistant<|end_header_id|>,\n",
    "    \"\"\",\n",
    "    input_variables=[\"questions\", \"document\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER GRADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0, format=\"json\")\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an answer is useful to resolve a question. Give a binary score 'yes' or 'no'\n",
    "    to indicate whether the answer is useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n -------- \\n\n",
    "    {generation}\n",
    "    \\n -------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>,\n",
    "    \"\"\",\n",
    "    input_variables=[\"questions\", \"document\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"generation\": generation, \"question\": user_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "# Define the state which will be passed between the steps\n",
    "class GraphState(TypedDict):\n",
    "    documents: List[str] #\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search : bool\n",
    "\n",
    "\n",
    "# Define the functions that will be executed in the graph\n",
    "def retrieve(state):\n",
    "    \"\"\" \n",
    "    Retrieve documents from the vectorstore\n",
    "    Args:\n",
    "        state (dict): Current graph state\n",
    "    Returns:\n",
    "        state (dict): Updated graph state with retrieved documents\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"------Retrieving documents------\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\" \n",
    "    Generate answer based on the retrieved documents\n",
    "    Args:\n",
    "        state (dict): Current graph state\n",
    "    Returns:\n",
    "        state (dict): Updated graph state with generated answer\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"------Generating answer------\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    generation = reg_chain.invoke({\"question\": question, \"context\": documents})\n",
    "    return {\"generation\": generation, \"question\": question, \"documents\": documents}    \n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\" \n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "    Args:\n",
    "        state (dict): Current graph state\n",
    "    Returns:\n",
    "        state (dict): Filtered out documents and updated web_search state\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"------Grading documents------\")\n",
    "    questions = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each document\n",
    "    filtered_docs = []\n",
    "    web_search = False\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": questions, \"document\": doc.page_content})\n",
    "        grade = score[\"score\"]\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"Document is relevant\")\n",
    "            filtered_docs.append(doc)\n",
    "        # Document is not relevant, set flag to run web search\n",
    "        else:\n",
    "            print(\"Document is not relevant\")\n",
    "            web_search = True\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": questions, \"web_search\": web_search}\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\" \n",
    "    Run web search to retrieve additional information\n",
    "    Args:\n",
    "        state (dict): Current graph state\n",
    "    Returns:\n",
    "        state (dict): Updated graph state with additional information from web search\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"------Running web search------\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Run web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([doc['content'] for doc in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONDITIONAL CHECKS FOR GRADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determine whether to generate an answer or add web search\n",
    "    \n",
    "    Args:\n",
    "        state (dict): Current graph state\n",
    "    \n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    print(\"------Deciding to generate answer or run web search------\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    fittered_docs = state[\"documents\"]\n",
    "    \n",
    "    if web_search:\n",
    "        # Will regenerate the answer with the new documents from web search\n",
    "        return \"web_search\"\n",
    "    else:\n",
    "        # We have all the relevant documents, generate the answer\n",
    "        return \"generate\"\n",
    "\n",
    "def check_answer(state):\n",
    "    \"\"\" \n",
    "    Determines whether the generated answer is grounded in the retrieved documents\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"------Checking HALLUCINATIONS------\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score[\"score\"]\n",
    "    \n",
    "    # Check whether is hallucination\n",
    "    if grade.lower() == 'yes':\n",
    "        print(\"Answer is grounded in the documents\")\n",
    "        # Check question answering\n",
    "        print(\"-----Grade Generation vs Question-----\")\n",
    "        score = answer_grader.invoke({\"generation\": generation, \"question\": question})\n",
    "        grade = score[\"score\"]\n",
    "        if grade.lower() == 'yes':\n",
    "            print(\"Answer is useful\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"Answer is not useful\")\n",
    "            return \"not_useful\"\n",
    "    else:\n",
    "        print(\"Answer is not grounded in the documents\")\n",
    "        return \"not_supported\"\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link all the above components and run the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Retrieving documents------\n",
      "Finished running: retrieve\n",
      "------Grading documents------\n",
      "Document is relevant\n",
      "Document is relevant\n",
      "Document is relevant\n",
      "Document is relevant\n",
      "------Deciding to generate answer or run web search------\n",
      "Finished running: grade_documents\n",
      "------Generating answer------\n",
      "------Checking HALLUCINATIONS------\n",
      "Answer is grounded in the documents\n",
      "-----Grade Generation vs Question-----\n",
      "Answer is useful\n",
      "Finished running: generate\n",
      "The first Hack TUES was held on March 10-13, 2022. It had an online format and the theme \"Space for everybody\".\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Adding nodes explicitly\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"run_web_search\", web_search)  # Renaming node to avoid conflict\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "# Build the graph\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\"grade_documents\", decide_to_generate, {\"generate\": \"generate\", \"web_search\": \"run_web_search\"})  # Updating reference\n",
    "workflow.add_edge(\"run_web_search\", \"generate\")\n",
    "workflow.add_conditional_edges(\"generate\", check_answer, {\"useful\": END, \"not_useful\": \"run_web_search\", \"not_supported\": \"generate\"})  # Updating reference\n",
    "\n",
    "# Execute the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Test\n",
    "from pprint import pprint\n",
    "inputs = {\"question\": \"When was the first Hack TUES?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Finished running: {key}\")\n",
    "print(value['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
